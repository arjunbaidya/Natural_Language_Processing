{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we will fine tune BERT Transformer model from Hugging Face on the custom dataset for detecting comments as Toxic or non-Toxic."
      ],
      "metadata": {
        "id": "oOvRtsWlsIxS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "RuRaP-P8sHHT"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "9b8USgj3sJ5d"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyQ0j0BDsXJo",
        "outputId": "b2adb5f7-d977-4f3d-a83b-4c272e850787"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/toxic_comments_train.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ponocUrPsZON",
        "outputId": "b21e3e81-755c-4b69-e08d-a67624ff7cf3"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id                                       comment_text  toxic  \\\n",
              "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
              "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "   severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0             0        0       0       0              0  \n",
              "1             0        0       0       0              0  \n",
              "2             0        0       0       0              0  \n",
              "3             0        0       0       0              0  \n",
              "4             0        0       0       0              0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdc1f8b1-476d-4935-944a-c580b2e38547\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdc1f8b1-476d-4935-944a-c580b2e38547')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cdc1f8b1-476d-4935-944a-c580b2e38547 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cdc1f8b1-476d-4935-944a-c580b2e38547');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2wzk9HvsbMd",
        "outputId": "a4095a19-aee5-4043-bc86-47947405f08d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "159571"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do a basic pre-processing of the comment text"
      ],
      "metadata": {
        "id": "zyOQOE2zudGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    '''Remove text in square brackets,remove links,remove punctuation\n",
        "    and remove words containing numbers.'''\n",
        "    \n",
        "    #pattern = [zero or more character]\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    \n",
        "    #pattern = with or without(http),://, one or more non-white space character, OR www, .,one or more non-white space character\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    \n",
        "    #pattern = <, zero or more characters, >, (one or more occurance of >)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    \n",
        "    #pattern = any punctionation\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    \n",
        "    #pattern = any new line\n",
        "    text = re.sub('\\n', ' ', text)\n",
        "    \n",
        "    #pattern = any from[a-zA-Z0-9_], any from[0-9], any from [a-zA-Z0-9_]\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "data['comment_text'] = data['comment_text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "XT1r34M8ujpd"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text in data['comment_text'][0:5]:\n",
        "  print(text, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsoWXIeJvXrw",
        "outputId": "df7503b1-ba56-464b-94c8-ac90fa6cdbef"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explanation Why the edits made under my username Hardcore Metallica Fan were reverted They werent vandalisms just closure on some GAs after I voted at New York Dolls FAC And please dont remove the template from the talk page since Im retired  \n",
            "\n",
            "Daww He matches this background colour Im seemingly stuck with Thanks  talk  January   UTC \n",
            "\n",
            "Hey man Im really not trying to edit war Its just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page He seems to care more about the formatting than the actual info \n",
            "\n",
            " More I cant make any real suggestions on improvement  I wondered if the section statistics should be later on or a subsection of types of accidents  I think the references may need tidying so that they are all in the exact same format ie date format etc I can do that later on if noone else does first  if you have any preferences for formatting style on references or want to do it yourself please let me know  There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up Its listed in the relevant form eg WikipediaGoodarticlenominationsTransport   \n",
            "\n",
            "You sir are my hero Any chance you remember what page thats on \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['non_toxic'] = data['toxic']+data['severe_toxic']+data['obscene']+data['threat']+data['insult']+data['identity_hate']\n",
        "\n",
        "# We will change the value to 1 (meaning non toxic) if the value is 0 and set it to 0 for all other cases\n",
        "data['non_toxic'] = data['non_toxic'].apply(lambda x: 1 if x==0 else 0)\n",
        "\n",
        "data[['non_toxic','toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum().plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "SHo_PfT6HMwl",
        "outputId": "047784b4-52e4-4016-c1c5-6cade6eaf6f0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see that the dataset is highly imbalanced. Let's make the training dataset balanced. We will club all categories that are other than Non-Toxic into the Toxic umbrella category."
      ],
      "metadata": {
        "id": "SrS2BZEgGsaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['toxic'] = np.where(data['non_toxic']==1, 0, 1)\n",
        "\n",
        "# We only need comments and label columns \n",
        "data = data[['comment_text', 'toxic']]   \n",
        "\n",
        "data_toxic = data[data['toxic']==1]\n",
        "data_nontoxic = data[data['toxic']==0]\n",
        "data = pd.concat([data_toxic, data_nontoxic.head(len(data_toxic))], axis=0)\n",
        "print(data['toxic'].value_counts())\n",
        "\n",
        "X = list(data['comment_text'])\n",
        "y = list(data['toxic'])\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, stratify=y, random_state=40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sowAAIdbGf0r",
        "outputId": "365cceda-347e-47b0-9b0c-85603a758a36"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    16225\n",
            "0    16225\n",
            "Name: toxic, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's keep a separate portion for the test set from the validation set\n",
        "\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_val, y_val, test_size=0.5, stratify=y_val, random_state=40)"
      ],
      "metadata": {
        "id": "C81B1ESO3T7r"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's define the Dataset class"
      ],
      "metadata": {
        "id": "LXneIgs-E4K6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the tokenizer object. Using bert-base-cased since I believe comments in all-caps could have a distinct meaning\n",
        "checkpoint = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "\n",
        "        self.labels = y\n",
        "        self.texts = [tokenizer(text, \n",
        "                                padding='max_length', \n",
        "                                max_length = 512, \n",
        "                                truncation=True,\n",
        "                                return_tensors=\"pt\") for text in X]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        texts = self.texts[idx]\n",
        "        label = np.array(self.labels[idx])\n",
        "        return texts, label"
      ],
      "metadata": {
        "id": "QA-6VPqqsjJ_"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's define the BERT Classifier"
      ],
      "metadata": {
        "id": "H9aPV84XFCX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 2)  # Since we have 2 classes in the Label\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "        return final_layer"
      ],
      "metadata": {
        "id": "Pt_3J6jMtu4A"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's create a training function to train the model"
      ],
      "metadata": {
        "id": "DTnnwGd0Emdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, X_train, y_train, X_val, y_val, learning_rate, epochs):\n",
        "\n",
        "    train = Dataset(X_train, y_train)\n",
        "    val = Dataset(X_val, y_val)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=16, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=16)\n",
        "\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    cuda_available = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if cuda_available else \"cpu\")    \n",
        "\n",
        "    if cuda_available:\n",
        "\n",
        "            model = model.cuda()\n",
        "            loss = loss.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                attention_mask = train_input['attention_mask'].to(device)\n",
        "                input_ids = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_ids, attention_mask)\n",
        "                \n",
        "                batch_loss = loss(output, train_label.long())\n",
        "                total_loss_train += batch_loss.item()\n",
        "                \n",
        "                accuracy = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += accuracy\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    attention_mask = val_input['attention_mask'].to(device)\n",
        "                    input_ids = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_ids, attention_mask)\n",
        "\n",
        "                    batch_loss = loss(output, val_label.long())\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    accuracy = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += accuracy\n",
        "            \n",
        "            print(f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(y_train): .3f} | Train Accuracy: {total_acc_train / len(y_train): .3f} | Val Loss: {total_loss_val / len(y_val): .3f} | Val Accuracy: {total_acc_val / len(y_val): .3f}')\n",
        "     "
      ],
      "metadata": {
        "id": "dx_B7z2xuDIu"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's create the evaluation function to test the model performance on the test set."
      ],
      "metadata": {
        "id": "kNQ1rILhEVGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X_test, y_test):\n",
        "\n",
        "    test = Dataset(X_test, y_test)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=32)\n",
        "\n",
        "    cuda_available = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
        "\n",
        "    if cuda_available:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "\n",
        "              test_label = test_label.to(device)\n",
        "              attention_mask = test_input['attention_mask'].to(device)\n",
        "              input_ids = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_ids, attention_mask)\n",
        "\n",
        "              accuracy = (output.argmax(dim=1) == test_label).sum().item()\n",
        "              total_acc_test += accuracy\n",
        "    \n",
        "    print(f'Test Accuracy: {total_acc_test / len(y_test): .3f}')"
      ],
      "metadata": {
        "id": "Posm-_iZuNwZ"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train the model now"
      ],
      "metadata": {
        "id": "b6RMYk-81-f7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 2\n",
        "LR = 1e-5\n",
        "model = BertClassifier()        \n",
        "train(model, X_train, y_train, X_val, y_val, LR, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFx1Me6ZuXMg",
        "outputId": "f40520be-3f59-4e4a-8a8e-878da04b8950"
      },
      "execution_count": 79,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 1522/1522 [35:28<00:00,  1.40s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 1 | Train Loss:  0.014 | Train Accuracy:  0.893 | Val Loss:  0.012 | Val Accuracy:  0.923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1522/1522 [35:27<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.007 | Train Accuracy:  0.959 | Val Loss:  0.013 | Val Accuracy:  0.925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model on the test set\n",
        "\n",
        "evaluate(model, X_test, y_test)"
      ],
      "metadata": {
        "id": "lPlm6jpEuX5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a67e0b-4dd5-474e-c958-78e92ce5c6f9"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.930\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try out the model with some sample comments"
      ],
      "metadata": {
        "id": "l-u0dYx92rrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "sample = [\"You are stupid enough to go there alone.\", \n",
        "          \"I am going home\", \n",
        "          \"fuck you!!\", \n",
        "          \"I love you more everyday.\", \n",
        "          \"I loved you but not anymore since I am now over you, so kindly leave me alone.\",\n",
        "          \"This course is shit! I'd rather learn on my own...\"]\n",
        "\n",
        "input = tokenizer(sample, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "attention_mask = input['attention_mask'].to(device)\n",
        "input_ids = input['input_ids'].squeeze(1).to(device)\n",
        "logits = model(input_ids, attention_mask)\n",
        "\n",
        "# Printing the model output logits\n",
        "print(logits)"
      ],
      "metadata": {
        "id": "_6JrKpfSz0n3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's convert the model output logits into probabilites by passing them through the Softmax function\n",
        "predictions = torch.nn.functional.softmax(logits, dim=-1)\n",
        "print(predictions)\n",
        "preds_array = predictions.detach().cpu().numpy()\n",
        "\n",
        "# Displaying the model predictions\n",
        "for i, pred in enumerate(preds_array):\n",
        "  if pred[0] > pred[1]:\n",
        "    print(\"\\nComment:\", sample[i],\"\\nPrediction: Not Toxic\", \"\\nProbability:\", pred[0])\n",
        "  else:\n",
        "    print(\"\\nComment:\", sample[i],\"\\nPrediction: Toxic\", \"\\nProbability:\", pred[1])\n"
      ],
      "metadata": {
        "id": "Q13yl41mH289",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd5b09cb-7411-49b2-801f-bc05edee093e"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0019, 0.9981],\n",
            "        [0.9635, 0.0365],\n",
            "        [0.0013, 0.9987],\n",
            "        [0.9292, 0.0708],\n",
            "        [0.8705, 0.1295],\n",
            "        [0.0026, 0.9974]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "Comment: You are stupid enough to go there alone. \n",
            "Prediction: Toxic \n",
            "Probability: 0.99808514\n",
            "\n",
            "Comment: I am going home \n",
            "Prediction: Not Toxic \n",
            "Probability: 0.96353376\n",
            "\n",
            "Comment: fuck you!! \n",
            "Prediction: Toxic \n",
            "Probability: 0.99870527\n",
            "\n",
            "Comment: I love you more everyday. \n",
            "Prediction: Not Toxic \n",
            "Probability: 0.9291661\n",
            "\n",
            "Comment: I loved you but not anymore since I am now over you, so kindly leave me alone. \n",
            "Prediction: Not Toxic \n",
            "Probability: 0.87054634\n",
            "\n",
            "Comment: This course is shit! I'd rather learn on my own... \n",
            "Prediction: Toxic \n",
            "Probability: 0.9973973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/toxic_comm_classifier.pt'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "bUvUwXTDZr5q"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "30--zoJN5Tsd"
      },
      "execution_count": 83,
      "outputs": []
    }
  ]
}